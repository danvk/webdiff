[[ch-inference]]
== Type Inference and Control Flow Analysis

For programming languages used in ((("statically typed languages")))((("explicitly typed languages")))industry, "statically typed" and "explicitly typed" have traditionally been synonymous. C, pass:[C++], Java: they all made you write out your types. But academic languages never conflated these two things: languages like ML and Haskell have long had sophisticated type inference systems, and this has begun to work its way into industry languages. pass:[C++] has added `auto`, and Java has added `var`. Newer languages like Rust and Swift have had type inference from the start.

TypeScript makes extensive use of((("type inference"))) type inference. Used well, this can dramatically reduce the number of type annotations your code requires to get full type safety. One of the easiest ways to tell a TypeScript beginner from a more experienced developer is by the number of type annotations. An experienced TypeScript developer will use relatively few annotations (but use them to great effect), while a beginner may drown their code in redundant type annotations.

In most languages, a variable has a type and it never changes. TypeScript is a bit different. A variable has a type _at a location_ in your code. The process by which its type changes due to surrounding code is known ((("control flow analysis")))as _control flow analysis_.

This chapter teaches you how to think about type inference and control flow analysis, shows you some of the problems that can arise with them, and tells you how to fix them. After reading it, you should have a good understanding of how TypeScript infers types, when you still need to write explicit type annotations, and when it's still a good idea to write type annotations even when a type can be inferred.


[role="less_space pagebreak-before"]
[[avoid-inferable]]
=== Item 18: Avoid Cluttering Your Code with Inferable Types

The first((("type annotations", "reducing use of", id="type-annotate-reduce")))((("type inference", "avoiding type annotations", id="type-infer-avoid-annotate"))) thing that many new TypeScript developers do when they convert a codebase from JavaScript is fill it with type annotations. TypeScript is about _types_, after all! But in TypeScript, many annotations are unnecessary. Declaring types for all your variables is counterproductive and is considered poor style.

Don’t write:

[source,ts]
----
let x: number = 12;
----

Instead, just write:

[source,ts]
----
let x = 12;
----

If you mouse over `x` in your editor, you’ll see that its type has been inferred as `number` (as shown in <<efts-3in1>>).

[[efts-3in1]]
.A text editor showing that the inferred type of ++x++ is number.
image::images/ets2_0301.png[]

The explicit type annotation is redundant. Writing it just adds noise. If you're unsure of the type, you can check it in your editor.

TypeScript((("objects", "type inference", id="object-type-infer"))) will also infer the types of more complex objects. Instead of:

[source,ts]
----
const person: {
  name: string;
  born: {
    where: string;
    when: string;
  };
  died: {
    where: string;
    when: string;
  }
} = {
  name: 'Sojourner Truth',
  born: {
    where: 'Swartekill, NY',
    when: 'c.1797',
  },
  died: {
    where: 'Battle Creek, MI',
    when: 'Nov. 26, 1883'
  }
};
----

[role="less_space pagebreak-before"]
you can just write:

// TODO: make sure the following code sample is on a single page.

[source,ts]
----
const person = {
  name: 'Sojourner Truth',
  born: {
    where: 'Swartekill, NY',
    when: 'c.1797',
  },
  died: {
    where: 'Battle Creek, MI',
    when: 'Nov. 26, 1883'
  }
};
----

Again, the types are exactly the same. Writing the type in addition to the value just adds noise here. (pass:[<a href="#widening" data-dir="forward">Item 20</a>] will explain how TypeScript infers types for ((("objects", "type inference", startref="object-type-infer")))object literals.)

What's true ((("arrays", "type inference")))for objects is also true for arrays. TypeScript has no trouble figuring out the return type of this function based on its inputs and operations:

[source,ts]
----
function square(nums: number[]) {
  return nums.map(x => x * x);
}
const squares = square([1, 2, 3, 4]);
//    ^? const squares: number[]
----

TypeScript may infer something more precise than what you expected. This is generally a good thing. For example:

[source,ts]
----
const axis1: string = 'x';
//    ^? const axis1: string
const axis2 = 'y';
//    ^? const axis2: "y"
----

`"y"` is a more precise type for the `axis2` variable. The explicit `string` annotation on `axis1` adds noise and reduces type safety.

Allowing types((("refactoring", "with type inference", secondary-sortas="type inference", id="refactor-type-infer"))) to be inferred can also facilitate refactoring. Say you have a `Product` type and a function to log it:

[source,ts]
----
interface Product {
  id: number;
  name: string;
  price: number;
}

function logProduct(product: Product) {
  const id: number = product.id;
  const name: string = product.name;
  const price: number = product.price;
  console.log(id, name, price);
}
----

[role="less_space pagebreak-before"]
At some point you learn that product IDs might have letters in them in addition to numbers. So you change the type of `id` in `Product`:

// verifier:prepend-to-following
[[inferable-product]]
[source,ts]
----
interface Product {
  id: string;
  name: string;
  price: number;
}
----

Because you included explicit annotations on all the variables in `logProduct`, this produces an error:

[source,ts]
----
function logProduct(product: Product) {
  const id: number = product.id;
     // ~~ Type 'string' is not assignable to type 'number'
  const name: string = product.name;
  const price: number = product.price;
  console.log(id, name, price);
}
----

Had you left off all the annotations in the `logProduct` function body, the code would have passed the type checker without modification (and worked correctly at runtime, too).

Here's a better implementation of `logProduct` that allows the types of all local variables to be inferred (it also switches to ((("destructuring assignment")))destructuring assignment):

[[log-product]]
[source,ts]
----
function logProduct(product: Product) {
  const {id, name, price} = product;
  console.log(id, name, price);
}
----

The corresponding version with explicit type annotations is repetitive and cluttered:

[source,ts]
----
function logProduct(product: Product) {
  const {id, name, price}: {id: string; name: string; price: number } = product;
  console.log(id, name, price);
}
----
// verifier:reset

You can't put type annotations directly inside the destructuring because, as pass:[<a data-dir="back" href="#type-value-space">Item 8</a>] explained, they would be interpreted as renaming directives in value space. Destructuring assignment is a great way to make your code more concise. It encourages consistent naming and it works much better with((("refactoring", "with type inference", secondary-sortas="type inference", startref="refactor-type-infer"))) inferred types.

Explicit type annotations are still required in some situations where TypeScript doesn’t have enough context to determine a type on its own. You have seen one of these before: function parameters.

Some((("function parameters", "type annotations with", id="function-parameter-type-annotate")))((("type annotations", "with function parameters", secondary-sortas="function parameters", id="type-annotate-function-params"))) languages will infer types for parameters based on their eventual usage, but TypeScript does not. In TypeScript, a variable's type is generally determined when it is first introduced. (pass:[<a href="#evolving-any">Item 25</a>] discusses an important exception to this rule.)

Ideal TypeScript code includes type annotations for function/method signatures but not for the local variables created in their bodies. This keeps noise to a minimum and lets readers focus on the implementation logic.

There are some situations where you can leave the type annotations off of function parameters, too. When there’s a default value, for example:

[source,ts]
----
function parseNumber(str: string, base=10) {
  //                              ^? (parameter) base: number
  // ...
}
----

Here the type of `base` is inferred as `number` because of the default value of `10`.

Parameter types can usually be inferred when the function is used as a callback for a library with type declarations. The declarations on `request` and `response` in this example using the express HTTP server library are not required:

////
// verifier:prepend-to-following
// verifier:include-node-module:@types/express
[source,ts]
----
import express from 'express';
const app = express();
----
////

// https://github.com/danvk/literate-ts/issues/225
[source,ts]
----
// Don't do this:
app.get('/health', (request: express.Request, response: express.Response) => {
  response.send('OK');
});

// Do this:
app.get('/health', (request, response) => {
  //                ^? (parameter) request: Request<...>
  response.send('OK');
  // ^? (parameter) response: Response<...>
});
----

pass:[<a href="#context-inference">Item 24</a>] has more to say about how context is used in ((("function parameters", "type annotations with", startref="function-parameter-type-annotate")))((("type annotations", "with function parameters", secondary-sortas="function parameters", startref="type-annotate-function-params")))type inference.

There are a few situations where you may still want to specify a type even where it can be inferred.

One is when you define an ((("object literals, type annotations with")))((("type annotations", "with object literals", secondary-sortas="object literals")))object literal:

// verifier:reset
// verifier:prepend-id-to-following:inferable-product
// verifier:prepend-id-to-following:log-product
[source,ts]
----
const elmo: Product = {
  name: 'Tickle Me Elmo',
  id: '048188 627152',
  price: 28.99,
};
----

When you specify a type on a definition like this, you ((("excess property checking", "enabling")))((("properties", "excess property checking", "enabling")))enable excess property checking (pass:[<a href="#excess-property-checking">Item 11</a>]). This can help catch errors, particularly for types with optional fields.

You also increase the odds that an error will be reported in the right place. If you leave off the annotation, a mistake in the object's definition will result in a type error where it's used, rather than where it's defined:

[source,ts]
----
const furby = {
  name: 'Furby',
  id: 630509430963,
  price: 35,
};
logProduct(furby);
//         ~~~~~ Argument ... is not assignable to parameter of type 'Product'
//               Types of property 'id' are incompatible
//               Type 'number' is not assignable to type 'string'
----

In a larger codebase, this type error could appear in a different file with no clear connection to the object definition. With an annotation, you get a more concise error in the exact place where the mistake was made:

[source,ts]
----
const furby: Product = {
   name: 'Furby',
   id: 630509430963,
// ~~ Type 'number' is not assignable to type 'string'
   price: 35,
};
logProduct(furby);
----
// verifier:reset

Similar considerations apply((("function return types, type annotations with", id="function-return-type-annotate")))((("type annotations", "with function return types", secondary-sortas="function return types", id="type-annotate-function-return"))) to a function's return type. You may still want to annotate this even when it can be inferred to ensure that implementation errors don't leak out into uses of the function. This is particularly important for exported functions that are part of a public API.

Say you have a function that retrieves a stock quote:

[source,ts]
----
function getQuote(ticker: string) {
  return fetch(`https://quotes.example.com/?q=${ticker}`)
      .then(response => response.json());
}
----

You decide to add a cache to avoid duplicating network requests:

// verifier:prepend-to-following
[source,ts]
----
const cache: {[ticker: string]: number} = {};
function getQuote(ticker: string) {
  if (ticker in cache) {
    return cache[ticker];
  }
  return fetch(`https://quotes.example.com/?q=${ticker}`)
      .then(response => response.json())
      .then(quote => {
        cache[ticker] = quote;
        return quote as number;
      });
}
----

There’s a mistake in this implementation, which you can see if you look at the inferred return type for `getQuote`:

[source,ts]
----
getQuote;
// ^? function getQuote(ticker: string): number | Promise<number>
----

You should really be returning `Promise.resolve(cache[ticker])` so that `getQuote` always returns a Promise. The mistake will most likely produce an error…but in the code that calls `getQuote`, rather than in `getQuote` itself:

////
// verifier:prepend-to-following
[source,ts]
----
function considerBuying(x: any) {}
----
////

[source,ts]
----
getQuote('MSFT').then(considerBuying);
//               ~~~~ Property 'then' does not exist on type
//                    'number | Promise<number>'
----

Had you annotated the intended return type (`Promise<number>`), the error would have been reported in the correct place:

// verifier:reset
[[get-quote-error]]
[source,ts]
----
const cache: {[ticker: string]: number} = {};
function getQuote(ticker: string): Promise<number> {
  if (ticker in cache) {
    return cache[ticker];
    // ~~~ Type 'number' is not assignable to type 'Promise<number>'
  }
  // ...
}
----
// verifier:reset

When you annotate the return type, it keeps implementation errors from manifesting as errors in user code. This is a particularly good idea for functions like `getQuote` that have multiple `return` statements. If you want TypeScript to check that all the ++return++s return the same type, you'll need to provide a type annotation to tell it your intent.

(pass:[<a href="#use-async-await">Item 27</a>] explains how async functions are an effective way to avoid this particular mistake.)

// TK2(shrink): Similar example in #use-async-await; OTOH they illustrate different points.

Writing out the return type may also help you think more clearly about your function: you should know what its input and output types are _before you implement it_. While the implementation may shift around a bit, the function's contract (its type signature) generally should not. This is similar in spirit to test-driven development (TDD),((("TDD (test-driven development)"))) in which you write the tests that exercise a function before you implement it. Writing the full type signature first helps get you the function you want, rather than the one the implementation makes expedient.

Another reason to annotate return types is if you want to use a ((("named types")))named type. You might choose not to write a return type for this function, for example:

[source,ts]
----
interface Vector2D { x: number; y: number; }
function add(a: Vector2D, b: Vector2D) {
  return { x: a.x + b.x, y: a.y + b.y };
}
----

TypeScript infers the return type as `{ x: number; y: number; }`. This is compatible with `Vector2D`, but it may be surprising to users of your code when they see `Vector2D` as a type of the input and not of the output (<<efts-03in02>>).

[[efts-03in02]]
.The parameters to the ++add++ function have named types, but the inferred return value does not.
image::images/ets2_0302.png[]

If you annotate the return type, the presentation is more straightforward. And if you've written documentation on the type (pass:[<a href="#use-tsdoc">Item 68</a>]), it will be associated with the returned value as well. As the complexity of the inferred return type increases, it becomes increasingly helpful to provide a name.

Finally, annotating your return types means that TypeScript has less work to do figuring them out. For large codebases, this can have an impact on compiler performance. pass:[<a href="#performance">Item 78</a>] has more guidance on what to do when your build gets slow.

So should you annotate return types? To reduce code and facilitate refactoring, the default answer is "no." But it shouldn't take much to tip you over to "yes.". If the function has multiple `return` statements, if it's part of a public API, or if you want to use a named return type, then((("function return types, type annotations with", startref="function-return-type-annotate")))((("type annotations", "with function return types", secondary-sortas="function return types", startref="type-annotate-function-return"))) add the annotation.

If you are using a linter, the typescript-eslint rule `no-inferrable-types` (note the variant spelling) can help ensure that all your type annotations are really necessary.

[role="notoc"]
==== Things to Remember

- Avoid writing type annotations when TypeScript can infer the same type.
- Ideal TypeScript code has type annotations in function/method signatures but not on local variables in their bodies.
- Consider using explicit annotations for object literals to enable excess property checking and ensure errors are reported close to where they occur.
- Don't annotate function return types unless the function has multiple returns, is part of a public API, or you want it to return((("type annotations", "reducing use of", startref="type-annotate-reduce")))((("type inference", "avoiding type annotations", startref="type-infer-avoid-annotate"))) a named type.



[[one-var-one-type]]
=== Item 19: Use Different Variables for Different Types

In JavaScript,((("type inference", "variables, avoiding reusing", id="type-infer-variables-reuse")))((("variables", "avoiding reusing", id="variable-avoid-reuse")))((("reusing variables, avoiding", id="reuse-variable-avoid"))) it's no problem to reuse a variable to hold a differently typed value for a different purpose:

////
// verifier:prepend-to-following
[source,ts]
----
function fetchProduct(id: string) {}
function fetchProductBySerialNumber(id: number) {}
----
////

[source,js]
----
let productId = "12-34-56";
fetchProduct(productId);  // Expects a string

productId = 123456;
fetchProductBySerialNumber(productId);  // Expects a number
----

In TypeScript, this results in two errors:

[source,ts]
----
let productId = "12-34-56";
fetchProduct(productId);

productId = 123456;
// ~~~~~~ Type 'number' is not assignable to type 'string'
fetchProductBySerialNumber(productId);
//                         ~~~~~~~~~
// Argument of type 'string' is not assignable to parameter of type 'number'
----

Hovering over the first `productId` in your editor gives a hint as to what's going on (see <<efts-03in03>>).

[[efts-03in03]]
.The inferred type of ++productId++ is ++string++.
image::images/ets2_0303.png[]

// TK2(mech): this image is too big

Based on the value `"12-34-56"`, TypeScript has inferred ++productId++'s type as `string`. You can't assign a `number` to a `string`, hence the error.

This leads us to a key insight about variables in TypeScript: _while a variable's value can change, its type generally does not_. The one common way a type can change is to narrow (pass:[<a href="#narrowing">Item 22</a>]), but this involves a type getting smaller, not expanding to include new values. pass:[<a href="#evolving-any">Item 25</a>] presents a notable exception to this rule, but it is an exception and not the rule.

How can you use this idea to fix the example? For ++productId++'s type to not change, it must be broad enough to encompass both ++string++s and ++number++s. This is the very definition of the((("union types"))) union type, `string|number`:

[source,ts]
----
let productId: string | number = "12-34-56";
fetchProduct(productId);

productId = 123456;  // OK
fetchProductBySerialNumber(productId);  // OK
----

This fixes the errors. It's interesting that TypeScript has been able to determine that `id` is really a `string` in the first call and really a `number` in the second. It has narrowed the union type based on the assignment.

// TK2: "interesting" or indicative that I need a better example here?

While a union type does work, it may create more issues down the road. Union types are harder to work with than simple types like `string` or `number` because you usually have to check what they are before you do anything with them.

[role="less_space pagebreak-before"]
The better solution is to introduce a new variable:

[source,ts]
----
const productId = "12-34-56";
fetchProduct(productId);

const serial = 123456;  // OK
fetchProductBySerialNumber(serial);  // OK
----

In the previous version, the first and second `productId` were not semantically related to one another. They were only related by the fact that you reused a variable. This was confusing for the type checker and would be confusing for a human reader, too.

The version with two variables is better for a number of reasons:

* It disentangles two unrelated concepts (ID and serial number).
* It allows you to use more specific variable names.
* It improves type inference. No type annotations are needed.
* It results in simpler types (string and number literals, rather than ++string|[.keep-together]#number#++).
* It lets you declare the variables `const` rather than `let`. This makes them easier for people and the type checker to reason about.

The general theme, which will come up repeatedly in this chapter, is that mutation makes it harder for the type checker to follow along with your code. Try to avoid type-changing variables. If you can use different names for different concepts, it will make your code clearer both to human readers and to the type checker. You should have far more `const` than `let`.

This is not to be confused ((("variables", "shadowed")))((("shadowed variables")))with "shadowed" variables, as in this example:

[source,ts]
----
const productId = "12-34-56";
fetchProduct(productId);

{
  const productId = 123456;  // OK
  fetchProductBySerialNumber(productId);  // OK
}
----

While these two ++productId++s share a name, they are actually two distinct variables with no relationship to one another. It's fine for them to have different types. While TypeScript is not confused by this, your human readers might be. In general it's better to use different names for different concepts. Many teams choose to disallow this sort of shadowing via linter rules such as eslint's `no-shadow`.

This item focused on scalar values, but similar considerations apply to objects. For more on that, see pass:[<a href="#all-at-once">Item 21</a>].

[role="notoc"]
==== Things to Remember

- While a variable's value can change, its type generally does not.
- To avoid confusion, both for human readers and for the type checker, avoid reusing variables for differently ((("type inference", "variables, avoiding reusing", startref="type-infer-variables-reuse")))((("variables", "avoiding reusing", startref="variable-avoid-reuse")))((("reusing variables, avoiding", startref="reuse-variable-avoid")))typed values.


[[widening]]
=== Item 20: Understand How a Variable Gets Its Type

As pass:[<a href="#types-as-sets">Item 7</a>] explained, ((("type inference", "type widening", id="type-infer-widen")))((("widening", id="widen")))((("variables", "type widening", id="variables-type-widening")))((("type widening", id="type-widen")))at runtime every variable has a single value. But at static analysis time, when TypeScript is checking your code, a variable has a set of _possible_ values, namely, its type. When you initialize a variable with a constant but don't provide a type, the type checker needs to decide on one. In other words, it needs to decide on a set of possible values from the single value that you specified. In TypeScript, this process is known as _widening_. Understanding it will help you make sense of errors and make more effective use of type annotations.

Suppose you're writing a library to work with vectors. You write out a type for a 3D vector and a function to get the value of any of its components:

// verifier:prepend-to-following
[source,ts]
----
interface Vector3 { x: number; y: number; z: number; }
function getComponent(vector: Vector3, axis: 'x' | 'y' | 'z') {
  return vector[axis];
}
----

But when you try to use it, TypeScript flags an error:

[source,ts]
----
let x = 'x';
let vec = {x: 10, y: 20, z: 30};
getComponent(vec, x);
//                ~ Argument of type 'string' is not assignable
//                  to parameter of type '"x" | "y" | "z"'
----

This code runs fine, so why the error?

The issue is that ++x++'s type is inferred as `string`, whereas the `getComponent` function expected a more specific type for its second argument. This is widening at work, and here it has led to a type error.

Widening is ambiguous in the sense that there are many possible types for any given value. In this statement, for example:

[source,ts]
----
const mixed = ['x', 1];
----

what should the type of `mixed` be? Here are a few possibilities:

- `('x' | 1)[]`
- `['x', 1]`
- `[string, number]`
- `readonly [string, number]`
- `(string|number)[]`
- `readonly (string|number)[]`
- `[any, any]`
- `any[]`

// TODO: a venn diagram (ala types as sets) might be instructive here.

Without more context, TypeScript has no way to know which one is "right." It has to guess at your intent. (In this case, it guesses `(string|number)[]`.) And smart as it is, TypeScript can't read your mind. It won't get this right 100% of the time. The result is inadvertent errors like the one we just saw.

In the initial example, the type of `x` is inferred as `string` because TypeScript chooses to allow code like this:

[source,ts]
----
let x = 'x';
x = 'a';
x = 'Four score and seven years ago...';
----

But it would also be valid JavaScript to write:

[source,js]
----
let x = 'x';
x = /x|y|z/;
x = ['x', 'y', 'z'];
----

In inferring the type of `x` as `string`, TypeScript attempts to strike a balance between specificity and flexibility. A variable's type won't change to something completely different after it's declared (pass:[<a href="#one-var-one-type">Item 19</a>]), so `string` makes more sense than `string|RegExp` or `string|string[]` or `any`.

The general rule for primitive values ((("let keyword")))assigned with `let` is that they expand to their "base type": `"x"` expands to `string`, `39` expands to `number`, `true` expands to `boolean` and so on. (`null` and `undefined` are handled differently, see pass:[<a href="#evolving-any">Item 25</a>].)

TypeScript gives you a few ways to control the process of widening. One is `const`. If you declare a ((("const construct", "type widening")))variable with `const` instead of `let`, it gets a narrower type. In fact, using `const` fixes the error in our original example:

[source,ts]
----
const x = 'x';
//    ^? const x: "x"
let vec = {x: 10, y: 20, z: 30};
getComponent(vec, x);  // OK
----

Because `x` cannot be reassigned, TypeScript is able to infer a more precise type without risk of inadvertently flagging errors on subsequent assignments. And because the string literal type `"x"` is assignable to `"x"|"y"|"z"`, the code passes the type checker.

`const` isn't a panacea, however. For objects and arrays, there is still ambiguity. The `mixed` example illustrated the issue for ((("arrays", "type inference")))arrays: should TypeScript infer a tuple type? What type should it infer for the elements?

Similar issues arise with ((("objects", "type inference", id="object-type-infer-widening")))objects. This code is fine in JavaScript:

[source,js]
----
const obj = {
  x: 1,
};
obj.x = 3;
obj.x = '3';
obj.y = 4;
obj.z = 5;
obj.name = 'Pythagoras';
----

The type of `obj` could be inferred anywhere along the spectrum of specificity. At the specific end is `{readonly x: 1}`. More general is `{x: number}`. More general still would be `{[key: string]: number}`, `object` or, most general of all, `any`, or `unknown`.

In the case of objects, TypeScript infers what it calls((("best common type"))) the "best common type." It determines this by treating each property as though it were assigned with `let`. So the type of `obj` comes out as `{x: number}`. This lets you reassign `obj.x` to a different number, but not to a `string`. And it prevents you from adding other properties via direct assignment. (This is a good reason to build objects all at once, as explained in pass:[<span class="keep-together"><a href="#all-at-once">Item 21</a></span>].)

So the last four statements are errors:

[source,ts]
----
const obj = {
  x: 1,
};
obj.x = 3;  // OK
obj.x = '3';
//  ~ Type 'string' is not assignable to type 'number'
obj.y = 4;
//  ~ Property 'y' does not exist on type '{ x: number; }'
obj.z = 5;
//  ~ Property 'z' does not exist on type '{ x: number; }'
obj.name = 'Pythagoras';
//  ~~~~ Property 'name' does not exist on type '{ x: number; }'
----

Again, TypeScript is trying to strike a balance between specificity and flexibility. It needs to infer a specific enough type to catch errors, but not such a specific type that it creates false positives. It does this by inferring a type of `number` for a property initialized to a value like `1`.

If you know better, there are a few ways to override TypeScript's default behavior. One is to supply an((("explicit type annotation")))((("type annotations", "explicit"))) explicit type annotation:

[source,ts]
----
const obj: { x: string | number } = { x: 1 };
//    ^? const obj: { x: string | number; }
----

Another is to provide additional context to the type checker, e.g., by passing the value as an argument to a function (pass:[<a href="#context-inference">Item 24</a>]).

A third way is with((("const assertions"))) a `const` assertion. This is not to be confused with `let` and `const`, which introduce symbols in value space. This is a purely type-level construct. Look at the different inferred types for these variables:

[source,ts]
----
const obj1 = { x: 1, y: 2 };
//    ^? const obj1: { x: number; y: number; }

const obj2 = { x: 1 as const, y: 2 };
//    ^? const obj2: { x: 1; y: number; }

const obj3 = { x: 1, y: 2 } as const;
//    ^? const obj3: { readonly x: 1; readonly y: 2; }
----

When you write `as const` after a value, TypeScript will infer the narrowest possible type for it. There is _no_ widening. For true constants, this is typically what you want. You can also use `as const` with arrays to infer a tuple type:

[source,ts]
----
const arr1 = [1, 2, 3];
//    ^? const arr1: number[]
const arr2 = [1, 2, 3] as const;
//    ^? const arr2: readonly [1, 2, 3]
----

Despite the ((("type assertions", "const assertions versus")))similar syntax, a `const` assertion should not be confused with a type assertion (`as T`). While type assertions are best avoided (pass:[<a href="#prefer-declarations-to-assertions">Item 9</a>]), a `const` assertion doesn't compromise type safety and is always OK.

There's a ((("tuples", "type inference")))handy trick if you want TypeScript to infer a tuple type instead of an array type, but still allow the type of each element in the tuple to widen to its base type / best common type:

[source,ts]
----
function tuple<T extends unknown[]>(...elements: T) { return elements; }

const arr3 = tuple(1, 2, 3);
//    ^? const arr3: [number, number, number]
const mix = tuple(4, 'five', true);
//    ^? const mix: [number, string, boolean]
----

The `tuple` function here serves no purpose at runtime, but guides TypeScript toward inferring the type you want. Another function that can guide inference is((("Object.freeze"))) JavaScript's `Object.freeze`:

[source,ts]
----
const frozenArray = Object.freeze([1, 2, 3]);
//    ^? const frozenArray: readonly number[]
const frozenObj = Object.freeze({x: 1, y: 2});
//    ^? const frozenObj: Readonly<{ x: 1; y: 2; }>
----

Like a `const` assertion, `Object.freeze` has introduced some `readonly` modifiers into the inferred types (though it displays differently, the type of `frozenObj` is exactly the same as `obj3`). Unlike a `const` assertion, the "freeze" will be enforced by your JavaScript runtime. But it's a shallow freeze/++readonly++, whereas a `const` assertion is deep. pass:[<a href="#readonly">Item 14</a>] discusses `readonly` and how it can help prevent mistakes.

Finally, a fourth way to control widening ((("satisfies operator")))is the `satisfies` operator. This ensures that a value, well, satisfies the requirements of a type and guides inference by preventing TypeScript from inferring a wider type. Here's how it works:

// verifier:prepend-to-following
[source,ts]
----
type Point = [number, number];
const capitals1 = { ny: [-73.7562, 42.6526], ca: [-121.4944, 38.5816] };
//    ^? const capitals1: { ny: number[]; ca: number[]; }

const capitals2 = {
  ny: [-73.7562, 42.6526], ca: [-121.4944, 38.5816]
} satisfies Record<string, Point>;
capitals2
// ^? const capitals2: { ny: [number, number]; ca: [number, number]; }
----

Left to its own devices, TypeScript takes the keys from the object literal and widens the values to `number[]`, just as it would with `let`. With `satisfies`, we prevent the values from being widened beyond the `Point` type.

Compare this to what you get from an annotation using the same type:

[source,ts]
----
const capitals3: Record<string, Point> = capitals2;
capitals3.pr;  // undefined at runtime
//        ^? Point
capitals2.pr;
//        ~~ Property 'pr' does not exist on type '{ ny: ...; ca: ...; }'
----

The type coming from `satisfies` has precise keys, which helps to catch errors.

The `satisfies` operator will report an error if part of the object isn't assignable to the type:

[source,ts]
----
const capitalsBad = {
    ny: [-73.7562, 42.6526, 148],
//  ~~ Type '[number, number, number]' is not assignable to type 'Point'.
    ca: [-121.4944, 38.5816, 26],
//  ~~ Type '[number, number, number]' is not assignable to type 'Point'.
} satisfies Record<string, Point>;
----

This is an improvement over a `const` assertion because it will report the error where you define the object, rather than where you use it.

If you're getting incorrect errors that you think are due to widening, consider changing `let` to `const`, adding some explicit type annotations, using a helper function like `tuple` or `Object.freeze`, or using a +const+ assertion or a `satisfies` clause. As always, inspecting types in your editor is the key to building an intuition for how this((("objects", "type inference", startref="object-type-infer-widening"))) works (see pass:[<a href="#editor">Item 6</a>]).

[role="notoc"]
==== Things to Remember

- Understand how TypeScript infers a type from a literal by widening it.
- Familiarize yourself with the ways you can affect this behavior: `const`, type annotations, context, helper((("type inference", "type widening", startref="type-infer-widen")))((("widening", startref="widen")))((("variables", "type widening", startref="variables-type-widening")))((("type widening", startref="type-widen"))) functions, `as const`, and `satisfies`.


[[all-at-once]]
=== Item 21: Create Objects All at Once

As pass:[<a href="#one-var-one-type">Item 19</a>] explained, ((("type inference", "building objects", id="type-infer-build-object")))((("objects", "building", id="object-build")))while a variable’s value may change, its type in TypeScript generally does not. This makes some JavaScript patterns easier to model in TypeScript than others. In particular, it means that you should prefer creating objects all at once, rather than piece by piece.

Here's one way to create an object representing a two-dimensional point in JavaScript:

[source,js]
----
const pt = {};
pt.x = 3;
pt.y = 4;
----

In TypeScript, this will produce errors on each assignment:

[source,ts]
----
const pt = {};
//    ^? const pt: {}
pt.x = 3;
// ~ Property 'x' does not exist on type '{}'
pt.y = 4;
// ~ Property 'y' does not exist on type '{}'
----

This is because the type of `pt` on the first line is inferred based on its value `{}`, and you may only assign to known properties.

You get the opposite problem if you define a `Point` interface:

// verifier:prepend-subset-to-following:1-1
[[point-definition]]
[source,ts]
----
interface Point { x: number; y: number; }
const pt: Point = {};
   // ~~ Type '{}' is missing the following properties from type 'Point': x, y
pt.x = 3;
pt.y = 4;
----

A ((("type assertions")))type assertion seems to offer a solution:

[source,ts]
----
const pt = {} as Point;
//    ^? const pt: Point
pt.x = 3;
pt.y = 4;  // OK
----

++++
<p>
The problem with this pattern is that TypeScript won't check that you've assigned <span class="keep-together">all the</span> properties to <code>pt</code> before using it. If you dropped the assignment to <code>pt.y</code>, <span class="keep-together">for example,</span> the code would still pass the type checker but might lead to <code>NaN</code>s or <span class="keep-together">runtime</span> exceptions. As <a href="#prefer-declarations-to-assertions">Item 9</a> explained, type assertions shouldn't be the first tool you reach for.</p>
++++

The best solution is to define the object all at once with a((("type declarations"))) type declaration:

[source,ts]
----
const pt: Point = {
  x: 3,
  y: 4,
};
----

If you need to build a larger object from smaller ones, avoid doing it in multiple steps:

// verifier:prepend-subset-to-following:1-2
[source,ts]
----
const pt = {x: 3, y: 4};
const id = {name: 'Pythagoras'};
const namedPoint = {};
Object.assign(namedPoint, pt, id);
namedPoint.name;
        // ~~~~ Property 'name' does not exist on type '{}'
----

You can build the larger object all at once instead ((("object spread syntax", id="object-spread-syntax")))using _object spread syntax_, `...`:

[source,ts]
----
const namedPoint = {...pt, ...id};
//    ^? const namedPoint: { name: string; x: number; y: number; }
namedPoint.name;  // OK
//         ^? (property) name: string
----

You can also use object spread syntax to build up objects field by field in a type-safe way. The key is to use a new variable on every update so that each gets a new type (pass:[<a href="#one-var-one-type">Item 19</a>]):

// verifier:reset
// verifier:prepend-subset-of-id-to-following:point-definition:1-1
[source,ts]
----
const pt0 = {};
const pt1 = {...pt0, x: 3};
const pt: Point = {...pt1, y: 4};  // OK
----
// verifier:reset

The type declaration on the final line ensures that we've added all the necessary properties. While this is a roundabout way to build up such a simple object, it can be a useful technique for adding properties to an object and allowing TypeScript to infer a new type.

// Stefan (2e) notes that spreading may have some performance overhead, but it seems pretty minor: https://stackoverflow.com/q/55843097/388951

To conditionally add a property in a type-safe way, you can use spread syntax with `{}` or any falsy value (`null`, `undefined`, `false`, etc.), which add no properties:

// verifier:tsconfig:exactOptionalPropertyTypes=true
// verifier:prepend-to-following
[source,ts]
----
declare let hasMiddle: boolean;
const firstLast = {first: 'Harry', last: 'Truman'};
const president = {...firstLast, ...(hasMiddle ? {middle: 'S'} : {})};
//    ^? const president: {
//         middle?: string;
//         first: string;
//         last: string;
//       }
// or: const president = {...firstLast, ...(hasMiddle && {middle: 'S'})};
----

As you can see, the inferred type has an optional property.

You can also use spread syntax to add multiple fields conditionally:

// verifier:reset
// verifier:tsconfig:exactOptionalPropertyTypes=true
// verifier:prepend-to-following
[source,ts]
----
declare let hasDates: boolean;
const nameTitle = {name: 'Khufu', title: 'Pharaoh'};
const pharaoh = { ...nameTitle, ...(hasDates && {start: -2589, end: -2566})};
//    ^? const pharaoh: {
//         start?: number;
//         end?: number;
//         name: string;
//         title: string;
//       }
----

In this case, both `start` and `end` have become optional fields. If you read `start` off this type, you'll have to consider the possibility ((("object spread syntax", startref="object-spread-syntax")))that it's `undefined`:

[source,ts]
----
const {start} = pharaoh;
//     ^? const start: number | undefined
----

Sometimes you want to build an object or array by transforming another one. In this case, the equivalent of "building objects all at once" is using built-in functional constructs or utility libraries((("functional constructs")))((("libraries", "type inference"))) like Lodash rather than loops. See pass:[<a href="#functional-libraries">Item 26</a>] for more on this.

[role="notoc"]
==== Things to Remember

- Prefer to build objects all at once rather than piecemeal.
- Use multiple objects and object spread syntax (`{...a, ...b}`) to add properties in a type-safe way.
- Know how to conditionally add properties ((("type inference", "building objects", startref="type-infer-build-object")))((("objects", "building", startref="object-build")))to an object.


[[narrowing]]
=== Item 22: Understand Type Narrowing

Narrowing, ((("type inference", "type narrowing", id="type-infer-narrow")))((("type narrowing", id="type-narrow")))((("narrowing types", id="narrow-type")))((("variables", "type narrowing", id="variable-type-narrow")))or "refinement," is the process by which TypeScript goes from a broad type to a more specific one. Perhaps the most common example of this is((("null checking"))) null [.keep-together]#checking:#

[source,ts]
----
const elem = document.getElementById('what-time-is-it');
//    ^? const elem: HTMLElement | null
if (elem) {
  elem.innerHTML = 'Party Time'.blink();
  // ^? const elem: HTMLElement
} else {
  elem
  // ^? const elem: null
  alert('No element #what-time-is-it');
}
----

[role="less_space pagebreak-before"]
If `elem` is `null`, then the code in the first branch won't execute. So TypeScript is able to exclude `null` from the union type within this block, resulting in a narrower type which is much easier to work with. Because the compiler is following the paths of execution of your code, this is also known as ((("control flow analysis")))control flow analysis. The type checker is generally quite good at following your logic and narrowing types in conditionals like these, though it can occasionally be thwarted by aliasing (pass:[<a href="#avoid-aliasing">Item 23</a>]).

Notice how the same symbol, `elem`, has different static types at different locations in your code. This is a somewhat unusual ability amongst programming languages: in [.keep-together]#pass:[C++]#, Java, and Rust, for example, a variable has a single type for its entire lifetime. If you want to narrow its type, you also need to create a new variable. But in TypeScript, a symbol has a type _at a location_. Learn to take advantage of this and you'll write more concise, idiomatic TypeScript.

There are many ways that you can narrow a type. Throwing or returning from a branch will ((("throwing (in type narrowing)")))narrow a variable's type for the rest of a block:

[source,ts]
----
const elem = document.getElementById('what-time-is-it');
//    ^? const elem: HTMLElement | null
if (!elem) throw new Error('Unable to find #what-time-is-it');
elem.innerHTML = 'Party Time'.blink();
// ^? const elem: HTMLElement
----

You can also ((("instanceof", "type narrowing")))use `instanceof`:

[source,ts]
----
function contains(text: string, search: string | RegExp) {
  if (search instanceof RegExp) {
    return !!search.exec(text);
    //       ^? (parameter) search: RegExp
  }
  return text.includes(search);
  //                   ^? (parameter) search: string
}
----

A ((("property checks (in type narrowing)")))property check also works:

[source,ts]
----
interface Apple { isGoodForBaking: boolean; }
interface Orange { numSlices: number; }
function pickFruit(fruit: Apple | Orange) {
  if ('isGoodForBaking' in fruit) {
    fruit
    // ^? (parameter) fruit: Apple
  } else {
    fruit
    // ^? (parameter) fruit: Orange
  }
  fruit
  // ^? (parameter) fruit: Apple | Orange
}
----

[role="less_space pagebreak-before"]
Some built-in functions((("Array.isArray"))) such as `Array.isArray` are also able to narrow types:

[source,ts]
----
function contains(text: string, terms: string | string[]) {
  const termList = Array.isArray(terms) ? terms : [terms];
  //    ^? const termList: string[]
  // ...
}
----

TypeScript is generally quite good at tracking types through ((("type assertions", "type narrowing")))((("union types", "excluding null")))((("null values", "excluding")))conditionals. Think twice before adding a type assertion—it might be on to something that you're not! For example, this is the wrong way to exclude `null` from a union type:

// verifier:include-node-module:@types/web
[source,ts]
----
const elem = document.getElementById('what-time-is-it');
//    ^? const elem: HTMLElement | null
if (typeof elem === 'object') {
  elem;
  // ^? const elem: HTMLElement | null
}
----

Because `typeof null` is `"object"` in JavaScript, you have not, in fact, excluded `null` with this check!footnote:[Why this quirk? The original JavaScript implementation represented objects with a type tag and a value. The tag for objects was 0, and `null` was represented as a null pointer (`0x0`), hence its type tag was `0`, and `typeof null` was `"object"`. The standards committee attempted to fix this bug in 2011 but it broke too many web sites.] Similar surprises can come from falsy primitive values:

[source,ts]
----
function maybeLogX(x?: number | string | null) {
  if (!x) {
    console.log(x);
    //          ^? (parameter) x: string | number | null | undefined
  }
}
----

Because the empty string and `0` are both falsy, `x` could still be a `string` or `number` in that branch. TypeScript is right!

// Josh mentions https://github.com/microsoft/TypeScript/issues/45329
// in this context: TS should at least narrow `string` to `""`.

Another common way ((("tagged unions", "helping type checker")))to help the type checker narrow your types is by putting an explicit "tag" on them:

[source,ts]
----
interface UploadEvent { type: 'upload'; filename: string; contents: string }
interface DownloadEvent { type: 'download'; filename: string; }
type AppEvent = UploadEvent | DownloadEvent;

function handleEvent(e: AppEvent) {
  switch (e.type) {
    case 'download':
      console.log('Download', e.filename);
      //                      ^? (parameter) e: DownloadEvent
      break;
    case 'upload':
      console.log('Upload', e.filename, e.contents.length, 'bytes');
      //                    ^? (parameter) e: UploadEvent
      break;
  }
}
----

This is known as a "tagged union" or "discriminated union," and it is ubiquitous in TypeScript. pass:[<a data-type="xref" href="#ch-design">Chapter 4</a>] will revisit this pattern. When you write `switch` statements, it's a good idea to test that you've covered all possibilities. pass:[<a href="#exhaustiveness">Item 59</a>] shows you how.

If TypeScript isn't able to figure out a type, you can introduce a special function to help it out:

// verifier:prepend-to-following
[source,ts]
----
function isInputElement(el: Element): el is HTMLInputElement {
  return 'value' in el;
}

function getElementContent(el: HTMLElement) {
  if (isInputElement(el)) {
    return el.value;
    //     ^? (parameter) el: HTMLInputElement
  }
  return el.textContent;
  //     ^? (parameter) el: HTMLElement
}
----

This is known ((("user-defined type guards")))((("type predicates")))((("type guards")))as a "user-defined type guard," and the `el is HTMLInputElement` clause is called a "type predicate." As a return type, this type tells the type checker that it can narrow the type of the parameter if the function returns true.

Some functions are able to use type guards to narrow types ((("arrays", "type narrowing")))((("objects", "type narrowing")))in arrays or objects, notably the `filter` method on ++Array++s:

[source,ts]
----
const formEls = document.querySelectorAll('.my-form *');
const formInputEls = [...formEls].filter(isInputElement);
//    ^? const formInputEls: HTMLInputElement[]
----
// verifier:reset
// filtering null values would be a simpler example, but my PR is in limbo: https://github.com/microsoft/TypeScript/pull/57465
// Filtering `null` and `undefined` values out of arrays is a common need and is the subject of #is-non-nullish.

It's important to note user-defined type guards are no safer than a type assertion (`el as HTMLInputElement`): there's nothing checking that the body of a type guard corresponds to the type predicate it returns. (In this case, in fact, there are a few ++Element++s with a `value` property that are not ++HTMLInputElement++s.) 

You can often rework your code slightly to help TypeScript follow along. This code using a `Map` is correct but produces a type error:

[role="less_space pagebreak-before"]
// verifier:prepend-subset-to-following:1-2
[source,ts]
----
const nameToNickname = new Map<string, string>();
declare let yourName: string;
let nameToUse: string;
if (nameToNickname.has(yourName)) {
  nameToUse = nameToNickname.get(yourName);
  // ~~~~~~ Type 'string | undefined' is not assignable to type 'string'.
} else {
  nameToUse = yourName;
}
----

The issue is that TypeScript doesn't understand the relationship between the `has` and `get` methods of a `Map`. It doesn't know that checking `has` eliminates the possibility of `undefined` in a subsequent lookup with `get`. A slight change eliminates the type error (and preserves the behavior):

[source,ts]
----
const nickname = nameToNickname.get(yourName);
let nameToUse: string;
if (nickname !== undefined) {
  nameToUse = nickname;
} else {
  nameToUse = yourName;
}
----

This pattern is common and can be written more concisely ((("?? (nullish coalescing) operator")))((("nullish coalescing operator")))using the "nullish coalescing" operator (`??`):

[source,ts]
----
const nameToUse = nameToNickname.get(yourName) ?? yourName;
----

If you find yourself fighting with the type checker in a conditional, think about whether you can rework it to help TypeScript follow along.

It's also helpful to understand when types _don't_ narrow. One notable example is in ((("callbacks", "type narrowing")))callbacks:

// verifier:reset
// verifier:prepend-to-following
[source,ts]
----
function logLaterIfNumber(obj: { value: string | number }) {
  if (typeof obj.value === "number") {
    setTimeout(() => console.log(obj.value.toFixed()));
    //                                     ~~~~~~~
    // Property 'toFixed' does not exist on type 'string | number'.
  }
}
----

We've done a `typeof` check which should narrow the type of `obj.value`. So why did it revert back to the union type, which produced a type error?

It's because the calling code might look like this:

[[cookie-monster-throw]]
[source,ts]
----
const obj: { value: string | number } = { value: 123 };
logLaterIfNumber(obj);
obj.value = 'Cookie Monster';
----

By the time the callback runs, the type of `obj.value` has changed, invalidating the refinement. This code throws an exception at runtime, and TypeScript is right to warn you about it.

////
[[cookie-monster-throw-output]]
----
setTimeout(() => console.log(obj.value.toFixed()));
                                               ^

TypeError: obj.value.toFixed is not a function
----
////

// Alternative example below

Understanding how types narrow will help you build an intuition for how type inference works, make sense of errors, and generally have a more productive relationship with the type checker.

[role="notoc"]
==== Things to Remember

- Understand how TypeScript narrows types based on conditionals and other types of control flow.
- Use tagged/discriminated unions and user-defined type guards to help the process of narrowing.
- Think about whether code can be refactored to let TypeScript follow((("type inference", "type narrowing", startref="type-infer-narrow")))((("type narrowing", startref="type-narrow")))((("narrowing types", startref="narrow-type")))((("variables", "type narrowing", startref="variable-type-narrow"))) along more easily.



[[avoid-aliasing]]
=== Item 23: Be Consistent in Your Use of Aliases

When ((("control flow analysis", id="control-flow-aliases")))((("aliases", "consistency in", id="aliases")))((("type inference", "aliases", id="type-infer-alias")))you introduce a new name for a value:

// verifier:prepend-to-following
[source,ts]
----
const place = {name: 'New York', latLng: [41.6868, -74.2692]};
const loc = place.latLng;
----

you have created an _alias_. Changes to properties on the alias will be visible on the original value as well:

++++
<pre data-type="programlisting">&gt; <strong>loc[0] = 0;</strong>
0
&gt; <strong>place.latLng</strong>
[ 0, -74.2692 ]</pre>
++++
// verifier:reset

If you've used a language that has pointer or reference types, this is the same idea. There are two variables that point to the same underlying object.

Aliases are the bane of compiler writers in all languages because they make control flow analysis difficult. If you're deliberate in your use of aliases, TypeScript will be able to understand your code better and help you find more real errors.

Suppose you have a data structure that represents a polygon:

// verifier:prepend-to-following
[source,ts]
----
interface Coordinate {
  x: number;
  y: number;
}

interface BoundingBox {
  x: [number, number];
  y: [number, number];
}

interface Polygon {
  exterior: Coordinate[];
  holes: Coordinate[][];
  bbox?: BoundingBox;
}
----

The geometry of the polygon is specified by the `exterior` and `holes` properties. (The `holes` array lets you represent doughnut shapes, which have holes in the interior.) The `bbox` property is an optimization that may or may not be present. You can use it to speed up a point-in-polygon check:

[source,ts]
----
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  if (polygon.bbox) {
    if (pt.x < polygon.bbox.x[0] || pt.x > polygon.bbox.x[1] ||
        pt.y < polygon.bbox.y[0] || pt.y > polygon.bbox.y[1]) {
      return false;
    }
  }

  // ... more complex check
}
----

// TODO: write unit tests for all these isPointInPolygon functions;
//       there were quite a few bugs in the first release.

This code works (and type checks) but is a bit repetitive: `polygon.bbox` appears five times in three lines! Here's an attempt to factor out an intermediate variable to reduce duplication:

[source,ts]
----
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  const box = polygon.bbox;
  if (polygon.bbox) {
    if (pt.x < box.x[0] || pt.x > box.x[1] ||
        //     ~~~                ~~~  'box' is possibly 'undefined'
        pt.y < box.y[0] || pt.y > box.y[1]) {
        //     ~~~                ~~~  'box' is possibly 'undefined'
      return false;
    }
  }
  // ...
}
----

This code still works, so why the error? By factoring out the `box` variable, you've created an alias for `polygon.bbox`, and this has thwarted the control flow analysis that quietly worked in the first example.

You can inspect the types of `box` and `polygon.bbox` to see what's happening:

[source,ts]
----
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  polygon.bbox
  //      ^? (property) Polygon.bbox?: BoundingBox | undefined
  const box = polygon.bbox;
  //    ^? const box: BoundingBox | undefined
  if (polygon.bbox) {
    console.log(polygon.bbox);
    //                  ^? (property) Polygon.bbox?: BoundingBox
    console.log(box);
    //          ^? const box: BoundingBox | undefined
  }
}
----

The property check refines the type of `polygon.bbox` but not the type of `box`, hence the errors. This leads us to the golden rule of aliasing: _if you introduce an alias, use it consistently_.

Using `box` in the property check fixes the error:

[source,ts]
----
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  const box = polygon.bbox;
  if (box) {
    if (pt.x < box.x[0] || pt.x > box.x[1] ||
        pt.y < box.y[0] || pt.y > box.y[1]) {  // OK
      return false;
    }
  }
  // ...
}
----

The type checker is happy now, but there's an issue for human readers. We're using two names for the same thing: `box` and `bbox`. This is a ((("distinction without a difference")))distinction without a difference (pass:[<a href="#language-of-domain">Item 41</a>]).

Object destructuring syntax ((("object destructuring syntax")))((("arrays", "object destructuring syntax")))((("nested structures")))rewards consistent naming by letting us write more concise code. You can even use it on arrays and nested structures:

[source,ts]
----
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  const {bbox} = polygon;
  if (bbox) {
    const {x, y} = bbox;
    if (pt.x < x[0] || pt.x > x[1] || pt.y < y[0] || pt.y > y[1]) {
      return false;
    }
  }
  // ...
}
----

A few other points:

- This code ((("properties", "aliases and", id="property-alias")))would have required more property checks if the `x` and `y` properties had been optional, rather than the whole `bbox` property. We benefited from following the advice of pass:[<a href="#null-values-to-perimeter">Item 33</a>], which discusses the importance of pushing null values to the perimeter of your types.

[role="less_space pagebreak-before"]
- An optional property was appropriate for `bbox` but would not have been appropriate for `holes`. If `holes` was optional, then it would be possible for it to be either missing or an empty array (`[]`). This would be a distinction without a difference. An empty array is a fine way to indicate "no holes."

In your interactions with the type checker, don't forget that aliasing can introduce confusion at runtime, too:

// verifier:prepend-to-following
[[calculate-polygon-bbox]]
[source,ts]
----
const {bbox} = polygon;
if (!bbox) {
  calculatePolygonBbox(polygon);  // Fills in polygon.bbox
  // Now polygon.bbox and bbox refer to different values!
}
----

TypeScript's control flow analysis tends to be quite good for local variables. But for properties you should be on guard:

[source,ts]
----
function expandABit(p: Polygon) { /* ... */ }

polygon.bbox
//      ^? (property) Polygon.bbox?: BoundingBox | undefined
if (polygon.bbox) {
  polygon.bbox
  //      ^? (property) Polygon.bbox?: BoundingBox
  expandABit(polygon);
  polygon.bbox
  //      ^? (property) Polygon.bbox?: BoundingBox
}
----

The call to `expandABit(polygon)` could very well un-set `polygon.bbox`, so it would be safer for the type to revert to `BoundingBox | undefined`. But this would get frustrating: you'd have to repeat your property checks every time you called a function. So TypeScript makes the pragmatic choice to assume the function does not invalidate its type refinements. pass:[<a href="#unsoundness">Item 48</a>] discusses other situations like this where TypeScript trades safety for convenience.

If you'd factored out a local `bbox` variable instead of using `polygon.bbox`, the type [.keep-together]#of `bbox`# would remain accurate, but it might no longer be the same value as [.keep-together]#`polygon.bbox`.# If you're concerned about these sorts of side effects, the best option is to pass a read-only version of `polygon` to the function (pass:[<a href="#readonly">Item 14</a>]). By preventing mutation, we also improve type safety. This is a concern specifically for object types (including arrays) because they are mutable. Primitive values (numbers, strings, etc.) are already ((("properties", "aliases and", startref="property-alias")))immutable.

[role="notoc less_space pagebreak-before"]
==== Things to Remember

- Aliasing can prevent TypeScript from narrowing types. If you create an alias for a variable, use it consistently.
- Be aware of how function calls can invalidate type refinements on properties. Trust refinements on local variables more ((("control flow analysis", startref="control-flow-aliases")))((("aliases", "consistency in", startref="aliases")))((("type inference", "aliases", startref="type-infer-alias")))than on properties.



[[context-inference]]
=== Item 24: Understand How Context Is Used in Type Inference

TypeScript ((("type inference", "context in", id="type-infer-context")))((("context in type inference", id="context-type-infer")))doesn't just infer types based on values. It also considers the context in which the value occurs. This usually works well but can sometimes lead to surprises. Understanding how context is used in type inference will help you identify and work around these surprises when they do occur.

In JavaScript, you can factor out an expression into a constant without changing the behavior of your code (so long as you don't alter execution order). In other words, these two statements are equivalent:

[source,js]
----
// Inline form
setLanguage('JavaScript');

// Reference form
let language = 'JavaScript';
setLanguage(language);
----

In TypeScript, this refactor still works:

[source,ts]
----
function setLanguage(language: string) { /* ... */ }

setLanguage('JavaScript');  // OK

let language = 'JavaScript';
setLanguage(language);  // OK
----

Now suppose you take to heart the advice of pass:[<a href="#avoid-strings">Item 35</a>] and replace the string type with a more precise union of string literal types:

// verifier:prepend-subset-to-following:1-2
[source,ts]
----
type Language = 'JavaScript' | 'TypeScript' | 'Python';
function setLanguage(language: Language) { /* ... */ }

setLanguage('JavaScript');  // OK

let language = 'JavaScript';
setLanguage(language);
//          ~~~~~~~~ Argument of type 'string' is not assignable
//                   to parameter of type 'Language'
----

What went wrong? With the inline form, TypeScript knows from the function declaration that the parameter is supposed to be of type `Language`. The string literal [.keep-together]#`'JavaScript'`# is assignable to this type, so this is OK. But when you factor out a variable, TypeScript must infer its type at the time of assignment. It applies the usual algorithm (pass:[<a href="#widening">Item 20</a>]) and infers `string`, which is not assignable to `Language`. Hence the error.

[NOTE]
Some languages are able to infer types for variables based on their eventual usage. But this can also be confusing. ((("Hejlsberg, Anders")))Anders Hejlsberg, the creator of TypeScript, refers to it as "spooky action at a distance." By and large, TypeScript determines the type of a variable when it is first introduced. For a notable exception to this rule, see pass:[<a href="#evolving-any">Item 25</a>].

There are two good ways to solve this problem. One is to constrain the possible values of `language` with a type annotation:

[source,ts]
----
let language: Language = 'JavaScript';
setLanguage(language);  // OK
----

This also has the benefit of flagging an error if there's a typo in the language—for example `'Typescript'` (it should be a capital "S").

The other solution is to make the variable constant:

[source,ts]
----
const language = 'JavaScript';
//    ^? const language: "JavaScript"
setLanguage(language);  // OK
----

// Ryan (2e) notes that `let language = 'JavaScript' as const` is a third solution. But… why? (`as const` is discussed below.)

By using `const`, we've told the type checker that this variable cannot change. So TypeScript can infer a more precise type for `language`, namely the string literal type [.keep-together]#+"JavaScript"+.# This is assignable to `Language` so the code type checks. Of course, if you do need to reassign `language`, then you'll need to use the type annotation.

The fundamental issue here is that we've separated the value from the context in which it's used. Sometimes this is OK, but often it is not. The rest of this item walks through a few cases where this loss of context can cause errors and shows you how to fix them.

[role="notoc"]
==== Tuple Types

In ((("tuples", "type inference", id="tuple-type-infer")))addition to string literal types, problems can come up with tuple types. Suppose you're working with a map visualization that lets you programmatically pan the map:

// verifier:prepend-subset-to-following:1-2
[source,ts]
----
// Parameter is a (latitude, longitude) pair.
function panTo(where: [number, number]) { /* ... */ }

panTo([10, 20]);  // OK

const loc = [10, 20];
//    ^? const loc: number[]
panTo(loc);
//    ~~~ Argument of type 'number[]' is not assignable to
//        parameter of type '[number, number]'
----

As before, you've separated a value from its context. In the first instance, `[10, 20]` is assignable to the tuple type `[number, number]`. In the second, TypeScript infers the type of `loc` as `number[]` (i.e., an array of numbers of unknown length). This is not assignable to the tuple type, since many arrays have the wrong number of elements.

So how can you fix this error without resorting to `any`? You've already declared it `const`, so that won't help. But you can still provide a type annotation to let TypeScript know precisely what you mean:

[source,ts]
----
const loc: [number, number] = [10, 20];
panTo(loc);  // OK
----

As pass:[<a href="#widening" data-dir="back">Item 20</a>] explained, another way is to provide a "const context." This tells TypeScript that you intend the value to be deeply constant, rather ((("const contexts")))than the shallow constant that `const` gives:

[source,ts]
----
const loc = [10, 20] as const;
//    ^? const loc: readonly [10, 20]
panTo(loc);
//    ~~~ The type 'readonly [10, 20]' is 'readonly'
//        and cannot be assigned to the mutable type '[number, number]'
----

The type of `loc` is now inferred as `readonly [10, 20]`, rather than `number[]`. Unfortunately this is _too_ precise! The type signature of `panTo` makes no promises that it won't modify the contents of its `where` parameter. Since the `loc` parameter has a `readonly` type, this won't do.

The best solution here is to add a `readonly` annotation to the `panTo` function:

// verifier:reset
// verifier:prepend-subset-to-following:1-1
[source,ts]
----
function panTo(where: readonly [number, number]) { /* ... */ }
const loc = [10, 20] as const;
panTo(loc);  // OK
----

If the type signature is outside your control, then you'll need to use an annotation. (pass:[<a href="#readonly">Item 14</a>] has more to say about `readonly` and type safety.)

`const` contexts can neatly solve issues around losing context in inference, but they do have an unfortunate downside: if you make a mistake in the definition (say you add a third element to the tuple), then the error will be flagged at the call site, not at the definition. This may be confusing, especially if the error occurs in a deeply nested object that's used far from where it's defined:

[source,ts]
----
const loc = [10, 20, 30] as const;  // error is really here.
panTo(loc);
//    ~~~ Argument of type 'readonly [10, 20, 30]' is not assignable to
//        parameter of type 'readonly [number, number]'
//          Source has 3 element(s) but target allows only 2.
----

For this reason, it's preferable to use the inline form or apply a ((("tuples", "type inference", startref="tuple-type-infer")))type declaration.

// TK1: there's also the `tuple` helper from #widening. Is this a better place to describe it? It should at least be mentioned.

[role="notoc"]
==== Objects

The ((("objects", "type inference", id="object-type-infer-context")))problem of separating a value from its context also comes up when you factor out a constant from a larger object that contains some string literals or tuples. For example:

// verifier:reset
[source,ts]
----
type Language = 'JavaScript' | 'TypeScript' | 'Python';
interface GovernedLanguage {
  language: Language;
  organization: string;
}

function complain(language: GovernedLanguage) { /* ... */ }

complain({ language: 'TypeScript', organization: 'Microsoft' });  // OK

const ts = {
  language: 'TypeScript',
  organization: 'Microsoft',
};
complain(ts);
//       ~~ Argument of type '{ language: string; organization: string; }'
//            is not assignable to parameter of type 'GovernedLanguage'
//          Types of property 'language' are incompatible
//            Type 'string' is not assignable to type 'Language'
----

In the `ts` object, the type of `language` is inferred as `string`. As before, the solution is to add a type annotation (`const ts: GovernedLanguage = ...`), use a const assertion (`as const`), or the `satisfies` ((("objects", "type inference", startref="object-type-infer-context")))operator (pass:[<a href="#widening">Item 20</a>]).

[role="notoc"]
==== Callbacks

When you ((("callbacks", "type inference", id="callback-type-infer")))pass a callback to another function, TypeScript uses context to infer the parameter types of the callback:

// verifier:reset
// verifier:prepend-subset-to-following:1-3
[source,ts]
----
function callWithRandomNumbers(fn: (n1: number, n2: number) => void) {
  fn(Math.random(), Math.random());
}

callWithRandomNumbers((a, b) => {
  //                   ^? (parameter) a: number
  console.log(a + b);
  //              ^? (parameter) b: number
});
----

The types of `a` and `b` are inferred as `number` because of the type declaration for [.keep-together]#`callWithRandomNumbers`#. If you factor the callback out into a constant, you lose that context and get `noImplicitAny` errors:

[source,ts]
----
const fn = (a, b) => {
  //        ~    Parameter 'a' implicitly has an 'any' type
  //           ~ Parameter 'b' implicitly has an 'any' type
  console.log(a + b);
}
callWithRandomNumbers(fn);
----

The solution is either to add type annotations to the parameters:

[source,ts]
----
const fn = (a: number, b: number) => {
  console.log(a + b);
}
callWithRandomNumbers(fn);
----

or to apply a type declaration to the entire function expression if one is available (see pass:[<a href="#type-entire-functions">Item 12</a>]). If the function is only used in one place, prefer the inline form since it reduces the need for ((("callbacks", "type inference", startref="callback-type-infer")))annotations.

[role="notoc"]
==== Things to Remember

- Be aware of how context is used in type inference.
- If factoring out a variable introduces a type error, maybe add a type [.keep-together]#annotation.#
- If the variable is truly a constant, use a const assertion (`as const`). But be aware that this may result in errors surfacing at use, rather than definition.
- Prefer inlining values where it's practical to reduce the need ((("type inference", "context in", startref="type-infer-context")))((("context in type inference", startref="context-type-infer")))for type annotations.




[[evolving-any]]
=== Item 25: Understand Evolving Types

++++
<p class="fix_tracking">
In TypeScript, a variable's type is generally determined when it is declared. After this, it can be <em>narrowed</em> (by checking if it is <code>null</code>, for instance; see  <a href="#narrowing">Item 22</a>), but it cannot expand to include new values. There is one notable exception to this, however, and that is "evolving types." Understanding how these work will reduce the need for type annotations in your code and help you read TypeScript code that uses this convenient pattern.</p>
++++

In((("type inference", "evolving types", id="type-infer-evolve")))((("evolving types", id="evolve-type")))((("arrays", "evolving types", id="array-evolve-type"))) JavaScript, you might write a function to generate a range of numbers, like this:

[source,js]
----
function range(start, limit) {
  const nums = [];
  for (let i = start; i < limit; i++) {
    nums.push(i);
  }
  return nums;
}
----

When you convert this to TypeScript, it works exactly as you'd expect:

[source,ts]
----
function range(start: number, limit: number) {
  const nums = [];
  for (let i = start; i < limit; i++) {
    nums.push(i);
  }
  return nums;
  //     ^? const nums: number[]
}
----

Upon closer inspection, however, it's surprising that this works! How does TypeScript know that the type of `nums` is `number[]` when it's initialized as `[]`, which could be an array of any type? Clearly TypeScript is not following its usual rules for deriving a type from a literal value (pass:[<a href="#widening">Item 20</a>]). Inspecting each of the three occurrences of `nums` to reveal its inferred type starts to tell the story:

[[type-safe-range]]
[source,ts]
----
function range(start: number, limit: number) {
  const nums = [];
  //    ^? const nums: any[]
  for (let i = start; i < limit; i++) {
    nums.push(i);
    // ^? const nums: any[]
  }
  return nums;
  //     ^? const nums: number[]
}
----

The type of `nums` starts as `any[]`, an undifferentiated array. But after we push `number` values onto it, its type "evolves" to become `number[]`.

This is distinct from narrowing (aka "refinement"). An empty array's type can expand by pushing different elements onto it:

[source,ts]
----
const result = [];
//    ^? const result: any[]
result.push('a');
result
// ^? const result: string[]
result.push(1);
result
// ^? const result: (string | number)[]
----

With conditionals, the type can even vary across branches. Here you can see the same behavior with a simple value, rather than an array:

[source,ts]
----
let value;
//  ^? let value: any
if (Math.random() < 0.5) {
  value = /hello/;
  value
  // ^? let value: RegExp
} else {
  value = 12;
  value
  // ^? let value: number
}
value
// ^? let value: number | RegExp
----

[NOTE]
====
This behavior can be confusing to follow in your editor since the type is only "evolved" _after_ you assign or push an element. Inspecting the type on the line with the assignment still shows `any` or `any[]`.
====

This construct is a convenient way to reduce the need for type annotations. You can use it in your own code, and you should recognize it in code that you read. It's sometimes known as "evolving any" because the variable implicitly has an `any` type, but this is not a dangerous `any` (more on that momentarily). It's also sometimes called "evolving ++let++&rdquo; or "evolving arrays."

Another case that triggers this "evolving" behavior is if a variable is initially set to `null` or `undefined`. This often comes up when you set a value in a `try`/`catch` block:

////
// verifier:prepend-to-following
[source,ts]
----
declare function doSomethingRiskyAndReturnANumber(): number;
----
////

[source,ts]
----
let value = null;
//  ^? let value: any
try {
  value = doSomethingRiskyAndReturnANumber();
  value
  // ^? let value: number
} catch (e) {
  console.warn('alas!');
}
value
// ^? let value: number | null
----
// verifier:reset

If you try to use an evolving type before you set it or push values onto it, you'll get an((("implicit any errors"))) implicit ++any++ error:

[source,ts]
----
function range(start: number, limit: number) {
  const nums = [];
  //    ~~~~ Variable 'nums' implicitly has type 'any[]' in some
  //         locations where its type cannot be determined
  if (start === limit) {
    return nums;
    //     ~~~~ Variable 'nums' implicitly has an 'any[]' type
  }
  for (let i = start; i < limit; i++) {
    nums.push(i);
  }
  return nums;
}
----

Put another way, evolving types are only `any` when you _write_ to them. If you try to _read_ from them while they're still `any`, you'll get an error. This isn't the scary `any` that pass:[<a href="#any" data-dir="back">Item 5</a>] warned you about. It won't spread through your application like other `any` types.

Implicit `any` types do not evolve through function calls. The arrow function here trips up inference:

// verifier:prepend-id-to-following:type-safe-range
[source,ts]
----
function makeSquares(start: number, limit: number) {
  const nums = [];
  //    ~~~~ Variable 'nums' implicitly has type 'any[]' in some locations
  range(start, limit).forEach(i => {
    nums.push(i * i);
  });
  return nums;
  //     ~~~~ Variable 'nums' implicitly has an 'any[]' type
}
----
// verifier:reset

Improved type inference is a good reason to prefer ++for-of++ loops to `forEach` loops in TypeScript. For this specific case, though, it would be better to use the built-in array `map` method to transform the array in a single statement, avoiding iteration and evolving types entirely. See pass:[<a href="#functional-libraries">Item 26</a>] for more on how functional constructs can help types flow.

Evolving types come with all the usual caveats about type inference. Is the correct type for your array really `(string|number)[]`? Or should it be `number[]` and you incorrectly pushed a `string`? You may still want to provide an explicit type annotation to get better error checking instead of using an evolving type, or at least annotate the return type of your function to make sure that implementation errors don't escape into the type signature (pass:[<a href="#avoid-inferable">Item 18</a>]).

When you build an array by ++push++ing elements onto it or set a value conditionally, consider whether you can use the evolving type construct to reduce the need for type annotations and to help types flow through your code.

[role="notoc"]
==== Things to Remember

- While TypeScript types typically only _refine_, the types of values initialized to `null`, `undefined`, or `[]` are allowed to _evolve_.
- Recognize and understand this construct where it occurs, and use it to reduce the need for type annotations in your own code.
- For better error checking, consider providing an explicit type annotation instead of using ((("type inference", "evolving types", startref="type-infer-evolve")))((("evolving types", startref="evolve-type")))((("arrays", "evolving types", startref="array-evolve-type")))evolving types.



[[functional-libraries]]
=== Item 26: Use Functional Constructs and Libraries to Help Types Flow

JavaScript has ((("functional constructs", id="functional-construct")))((("libraries", "type inference", id="library")))((("type inference", "functional constructs and utility libraries", id="type-infer-library")))never included the sort of standard library you find in Python, C, or Java. Over the years, many libraries have tried to fill the gap. jQuery provided helpers not just for interacting with the DOM but also for iterating and mapping over objects and arrays. Underscore focused more on providing general utility functions, and Lodash built on this effort. Today libraries like Ramda continue to bring ideas from functional programming into the JavaScript world.

Some features from these libraries, such as `map`, `flatMap`, `filter`, and `reduce`, have made it into the JavaScript language itself. While these constructs (and the other ones provided by Lodash) are helpful in JavaScript and often preferable to a hand-rolled loop, this advantage tends to get even more lopsided when you add TypeScript to the mix. This is because their type declarations ensure that types flow through these constructs. With hand-rolled loops, you're responsible for the types yourself.

For example, consider parsing some CSV data. You could do it in plain JavaScript in a somewhat imperative style:

// verifier:prepend-subset-to-following:1-3
[[nba-js]]
[source,js]
----
const csvData = "...";
const rawRows = csvData.split('\n');
const headers = rawRows[0].split(',');

const rows = rawRows.slice(1).map((rowStr) => {
  const row = {};
  rowStr.split(",").forEach((val, j) => {
    row[headers[j]] = val;
  });
  return row;
});
----

More functionally minded JavaScripters might prefer to build the row objects with `reduce`:

[source,js]
----
const rows = rawRows.slice(1)
  .map((rowStr) =>
    rowStr
      .split(",")
      .reduce((row, val, i) => ((row[headers[i]] = val), row), {})
  );
----

This version saves a few characters but may be more cryptic depending on your sensibilities. ((("Lodash", id="lodash")))Lodash's `zipObject` function, which forms an object by "zipping" up arrays of keys and values, can tighten it even further:

// verifier:include-node-module:@types/lodash
// verifier:prepend-subset-to-following:1-1
[source,ts]
----
import _ from 'lodash';
const rows = rawRows.slice(1)
    .map(rowStr => _.zipObject(headers, rowStr.split(',')));
----

// This is the "native" version which is messier because of the type signature of Object.fromEntries:
// const rowsNative = rawRows.slice(1).map(
//   rowStr => Object.fromEntries(rowStr.split(',').map((cell, i) => [headers[i], cell]))
// );

Personally, I find this the clearest of all. But is it worth the cost of adding a dependency on a third-party library to your project and requiring all your coworkers to learn how to use it?

When you add TypeScript to the mix, it starts to tip the balance more strongly in favor of the Lodash solution.

Both vanilla JavaScript versions of the CSV parser produce the same error in [.keep-together]#TypeScript:#

[source,ts]
----
const rowsImperative = rawRows.slice(1).map(rowStr => {
  const row = {};
  rowStr.split(',').forEach((val, j) => {
    row[headers[j]] = val;
    // ~~~~~~~~~~~~ No index signature with a parameter of
    //              type 'string' was found on type '{}'
  });
  return row;
});
const rowsFunctional = rawRows.slice(1)
  .map((rowStr) =>
    rowStr
      .split(",")
      .reduce(
        (row, val, i) => ((row[headers[i]] = val), row),
        //                 ~~~~~~~~~~~~~~~ No index signature with a parameter of
        //                                 type 'string' was found on type '{}'
        {}
      )
  );
----

The solution in each case is to provide a type annotation for `{}`, either `{[column: string]: string}` or `Record<string, string>`.

The Lodash version, on the other hand, passes the type checker without modification:

[source,ts]
----
const rowsLodash =
  rawRows.slice(1).map(rowStr => _.zipObject(headers, rowStr.split(',')));
rowsLodash
// ^? const rowsLodash: _.Dictionary<string>[]
----

`Dictionary` is a Lodash type alias. `Dictionary<string>` is the same as `{[key: string]: string}` or `Record<string, string>`. The important thing here is that the type of `rows` is exactly correct, no type annotations needed.

These advantages get more pronounced as your data munging gets more elaborate. For example, suppose you have an object containing a list of the players on each team in the NBA:

// verifier:prepend-to-following
[source,ts]
----
interface BasketballPlayer {
  name: string;
  team: string;
  salary: number;
}
declare const rosters: {[team: string]: BasketballPlayer[]};
----

To build a flat list using a loop, you might use `concat` with an array. This code runs fine but does not type check:

[source,ts]
----
let allPlayers = [];
//  ~~~~~~~~~~ Variable 'allPlayers' implicitly has type 'any[]'
//             in some locations where its type cannot be determined
for (const players of Object.values(rosters)) {
  allPlayers = allPlayers.concat(players);
  //           ~~~~~~~~~~ Variable 'allPlayers' implicitly has an 'any[]' type
}
----

(The `concat` method does not trigger the "evolving" behavior described in pass:[<a href="#evolving-any" data-dir="back">Item 25</a>].)

To fix the error you need to add a type annotation to `allPlayers`:

[source,ts]
----
let allPlayers: BasketballPlayer[] = [];
for (const players of Object.values(rosters)) {
  allPlayers = allPlayers.concat(players);  // OK
}
----

But a better solution is to use `Array.prototype.flat`:

// verifier:prepend-to-following
[source,ts]
----
const allPlayers = Object.values(rosters).flat(); // OK
//    ^? const allPlayers: BasketballPlayer[]
----

The `flat` method flattens a multidimensional array. Its type signature is something like `T[][] => T[]`.footnote:[The `flat` method also takes a `depth` parameter which complicates the type declarations.] This version is the most concise and requires no type annotations. As an added bonus you can use `const` instead of `let` to prevent future mutations to the `allPlayers` variable.

Say you want to start with `allPlayers` and make a list of the highest-paid players on each team, ordered by salary.

Here's a solution without Lodash. It requires a type annotation wherever you don't use functional constructs:

[source,ts]
----
const teamToPlayers: {[team: string]: BasketballPlayer[]} = {};
for (const player of allPlayers) {
  const {team} = player;
  teamToPlayers[team] = teamToPlayers[team] || [];
  teamToPlayers[team].push(player);
}

for (const players of Object.values(teamToPlayers)) {
  players.sort((a, b) => b.salary - a.salary);
}

const bestPaid = Object.values(teamToPlayers).map(players => players[0]);
bestPaid.sort((playerA, playerB) => playerB.salary - playerA.salary);
console.log(bestPaid);
----

Here's the output:

----
[
  { team: 'GSW', salary: 51915615, name: 'Stephen Curry' },
  { team: 'PHO', salary: 47649433, name: 'Kevin Durant' },
  { team: 'DEN', salary: 47607350, name: 'Nikola Jokić' },
  { team: 'PHI', salary: 47607350, name: 'Joel Embiid' },
  { team: 'LAL', salary: 47607350, name: 'LeBron James' },
  ...
]
----

Here's the equivalent with Lodash:

[source,ts]
----
const bestPaid = _(allPlayers)
  .groupBy(player => player.team)
  .mapValues(players => _.maxBy(players, p => p.salary)!)
  .values()
  .sortBy(p => -p.salary)
  .value();
console.log(bestPaid.slice(0, 10));
//          ^? const bestPaid: BasketballPlayer[]
----

// TODO The Object.groupBy proposal is stage 3 and may be more widely adopted by publication
// https://caniuse.com/?search=Object.groupBy

In addition to being half the length, this code only requires a single non-null assertion (the type checker doesn't know that the `players` array passed to `_.maxBy` is non-empty). It makes use of a "chain," a concept in Lodash and Underscore that lets you write a sequence of operations in a more natural order. Instead of writing:

----
_.c(_.b(_.a(v)))
----

you write:

----
_(v).a().b().c().value()
----

The `_(v)` "wraps" the value, and the `.value()` "unwraps" it.

You can inspect each function call in the chain to see the type of the wrapped value. It's always correct.

It's not a ((("Lodash", startref="lodash")))coincidence that types flow so well through built-in functional constructs and those in libraries like Lodash. By avoiding mutation and returning new values from every call, they are able to produce new types as well (pass:[<a href="#one-var-one-type">Item 19</a>]). To a large extent, the development of TypeScript has been driven by an attempt to accurately model the behavior of JavaScript libraries in the wild. Take advantage of all this work and use them!

[role="notoc"]
==== Things to Remember

- Use built-in functional constructs and those in utility libraries like Lodash instead of hand-rolled constructs to improve type flow, increase legibility, and reduce the need for ((("functional constructs", startref="functional-construct")))((("libraries", "type inference", startref="library")))((("type inference", "functional constructs and utility libraries", startref="type-infer-library")))explicit type annotations.



[[use-async-await]]
=== Item 27: Use async Functions Instead of Callbacks to Improve Type Flow

Classic JavaScript ((("type inference", "async functions", id="type-infer-async")))((("type inference", "callbacks", id="type-infer-callback")))((("type inference", "Promises", id="type-infer-promise")))((("async functions", id="async-function")))((("callbacks", "async functions instead", id="callback-async")))((("Promises", id="promises")))modeled asynchronous behavior using callbacks. This led to the infamous "pyramid of doom":

// verifier:prepend-to-following
[[pyramid-of-doom]]
[source,ts]
----
declare function fetchURL(
  url: string, callback: (response: string) => void
): void;

fetchURL(url1, function(response1) {
  fetchURL(url2, function(response2) {
    fetchURL(url3, function(response3) {
      // ...
      console.log(1);
    });
    console.log(2);
  });
  console.log(3);
});
console.log(4);

// Logs:
// 4
// 3
// 2
// 1
----

This code is heavily nested and, as you can see from the logs, the execution order is the opposite of the code order. This makes callback code hard to read. It gets even more confusing if you want to run the requests concurrently or bail when an error occurs.

ES2015 introduced the concept of a Promise to break the pyramid of doom. A Promise represents something that will be available in the future (they're also sometimes called "futures"). Here's the same code using Promises:

[source,ts]
----
const page1Promise = fetch(url1);
page1Promise.then(response1 => {
  return fetch(url2);
}).then(response2 => {
  return fetch(url3);
}).then(response3 => {
  // ...
}).catch(error => {
  // ...
});
----

Now there's less nesting, and the execution order more directly matches the code order. It's also easier to consolidate error handling and use higher-order tools like `Promise.all`.

ES2017 introduced ((("await keyword", id="await")))the `async` and `await` keywords to make things even more concise:

[source,ts]
----
async function fetchPages() {
  const response1 = await fetch(url1);
  const response2 = await fetch(url2);
  const response3 = await fetch(url3);
  // ...
}
----

The `await` keyword pauses execution of the `fetchPages` function until each Promise resolves. Within an `async` function, ++await++ing a Promise that rejects will throw an exception. This lets you use the usual ++try/catch++ machinery:

[source,ts]
----
async function fetchPages() {
  try {
    const response1 = await fetch(url1);
    const response2 = await fetch(url2);
    const response3 = await fetch(url3);
    // ...
  } catch (e) {
    // ...
  }
}
----

Just like exceptions, Promise rejections in TypeScript are untyped.

`async` and `await` are supported by all recent JavaScript runtimes, but even if you target ES5 or earlier, the TypeScript compiler will perform some elaborate transformations to make `async` and `await` work. In other words, whatever your runtime, with TypeScript you can use `async`/`await`.

There are a few good reasons to prefer Promises or `async`/`await` to callbacks:

* Promises are easier to compose than callbacks.
* Types are able to flow through Promises more easily than callbacks.

If you want to fetch the pages concurrently, for example, you can compose Promises with `Promise.all`:

[role="less_space pagebreak-before"]
[source,ts]
----
async function fetchPages() {
  const [response1, response2, response3] = await Promise.all([
    fetch(url1), fetch(url2), fetch(url3)
  ]);
  // ...
}
----

Using destructuring assignment with `await` is particularly nice in this context.

TypeScript is able to infer the types of each of the three `response` variables as `Response`. The equivalent code to issue the requests concurrently with callbacks requires more machinery and a type annotation:

[source,ts]
----
function fetchPagesWithCallbacks() {
  let numDone = 0;
  const responses: string[] = [];
  const done = () => {
    const [response1, response2, response3] = responses;
    // ...
  };
  const urls = [url1, url2, url3];
  urls.forEach((url, i) => {
    fetchURL(url, r => {
      responses[i] = url;
      numDone++;
      if (numDone === urls.length) done();
    });
  });
}
----

Extending this to include error handling or to be as generic as `Promise.all` is pass:[<span class="keep-together">challenging.</span>]

Type inference also works well with `Promise.race`, which resolves when the first of its input Promises resolves. You can use this to add timeouts to Promises in a general way:

[source,ts]
----
function timeout(timeoutMs: number): Promise<never> {
  return new Promise((resolve, reject) => {
     setTimeout(() => reject('timeout'), timeoutMs);
  });
}

async function fetchWithTimeout(url: string, timeoutMs: number) {
  return Promise.race([fetch(url), timeout(timeoutMs)]);
}
----

The return type of `fetchWithTimeout` is inferred as `Promise<Response>`, no type annotations required. It's interesting to dig into why this works: the return type of `Promise.race` is the union of the types of its inputs, in this case `Promise<Response | never>`. But taking a union with `never` (the empty set) is a no-op, so this gets [.keep-together]#simplified# to `Promise<Response>`. When you work with Promises, all of TypeScript's type inference machinery works to get you the right types.

// TK2 Josh would like some discussion of Promise<void>.
// -> it doesn't work here since the return type comes out as Promise<Response | void>, whereas with never it reduces to just Promise<Response>.

You may occasionally need to use raw Promises, notably when you are wrapping a callback API like `setTimeout`. But if you have a choice, you should generally prefer `async`/+await+ to raw Promises for two reasons:

* It typically produces more concise and straightforward code.
* It enforces that `async` functions always return Promises.

This latter property helps avoid a confusing class of bugs. By definition, an `async` function always returns a `Promise`. This is true even if it doesn't `await` anything. TypeScript can help you build an intuition for this:

[source,ts]
----
async function getNumber() { return 42; }
//             ^? function getNumber(): Promise<number>
----

You can also create `async` arrow functions:

[source,ts]
----
const getNumber = async () => 42;
//    ^? const getNumber: () => Promise<number>
----

The raw Promise equivalent is:

[source,ts]
----
const getNumber = () => Promise.resolve(42);
//    ^? const getNumber: () => Promise<number>
----

While it may seem odd to return a Promise for an immediately available value, this actually helps enforce an important rule: a ((("functions", "running synchronously/asynchronously")))function should either always be run synchronously or always be run asynchronously. It should never mix the two.

To see how breaking this rule can lead to chaos, let's try to add a cache to the `fetchURL` function:

// TODO: Similar example in #avoid-inferable

// verifier:prepend-to-following
[source,ts]
----
// Don't do this!
const _cache: {[url: string]: string} = {};
function fetchWithCache(url: string, callback: (text: string) => void) {
  if (url in _cache) {
    callback(_cache[url]);
  } else {
    fetchURL(url, text => {
      _cache[url] = text;
      callback(text);
    });
  }
}
----

While invoking the callback immediately may seem like an optimization, the function is now extremely difficult for a client to use:

[source,ts]
----
let requestStatus: 'loading' | 'success' | 'error';
function getUser(userId: string) {
  fetchWithCache(`/user/${userId}`, profile => {
    requestStatus = 'success';
  });
  requestStatus = 'loading';
}
----

What will the value of `requestStatus` be after calling `getUser`? It depends entirely on whether the profile is cached. If it's not, `requestStatus` will be set to "success." If it is, it'll get set to "success" and then set back to "loading." Oops!

Using `async` for both functions enforces consistent behavior:

// verifier:reset
[source,ts]
----
const _cache: {[url: string]: string} = {};
async function fetchWithCache(url: string) {
  if (url in _cache) {
    return _cache[url];
  }
  const response = await fetch(url);
  const text = await response.text();
  _cache[url] = text;
  return text;
}

let requestStatus: 'loading' | 'success' | 'error';
async function getUser(userId: string) {
  requestStatus = 'loading';
  const profile = await fetchWithCache(`/user/${userId}`);
  requestStatus = 'success';
}
----

// TK2(shrink): similar example in #avoid-inferable

Now it's completely transparent that `requestStatus` will end in "success." It's easy to accidentally produce half-synchronous code with callbacks or raw Promises, but difficult with `async`.footnote:[There's still a more subtle bug in this version: if you call ++fetchWithCache++ twice in a row with the same URL, it will issue two requests. How would you fix this?]

// This is the fix, it's three lines longer but I think it adds complexity that's irrelevant to the point that I'm trying to make here. https://www.typescriptlang.org/play?#code/MYewdgzgLgBA+sAhsAFgUwFwwN4G0CuATgDZbSECWYA5gLpYAKhIAthRGgDwBKaEADuA4A+AL4wAvDlEBuAFCIIATzDAYAM3yqoFcBrRRUAdQpQUAYWToAFEVIxyVagEpGzNhx59BkNMJxyMDAU6jC2JMFg8EioaM4BQUGEBkRRCFZoBCS08kGigTCgkLDqBqgMkvqGKOHEzrnRGVnEtJWl1QwNyVCpVeXy+YoqapraulHtqAAqaAAeUCZmlrG1ZFCUNK4wTKzsXI40-tgFRdAwyQJCaJWIAO6Ipn0oixYZtfUF3b0XPhwAdFA5lBrB98nJiAZzmgAI74PhQADKUEQPQgWAA5MQQIgACZOdEwAA+MHREHwwGAfAgBOJ6LQhGYhHR8iGqg0WmAOj01AMAFUOIRbAKAJI4tYbFwJKGw+FIlH4CCVTHYvE0ZknISwfjMdQUCE3e6PSYoGbzF7LGwAAwA9Ar6daACTYO2EUWiS0fJIwuHQOWopVkilU9X5IA

Note that if you return a Promise from an `async` function, it will not get wrapped in another Promise: the return type will be `Promise<T>` rather than ++Promise&#x200b;&lt;Promise&lt;T&gt;&gt;++. Again, TypeScript will help you build an intuition for this:

[source,ts]
----
async function getJSON(url: string) {
  const response = await fetch(url);
  const jsonPromise = response.json();
  return jsonPromise;
  //     ^? const jsonPromise: Promise<any>
}
getJSON
// ^? function getJSON(url: string): Promise<any>
----

[role="notoc"]
==== Things to Remember

- Prefer Promises to callbacks for better composability and type flow.
- Prefer `async` and `await` to raw Promises when possible. They produce more concise, straightforward code and eliminate whole classes of errors.
- If a function returns a Promise, ((("type inference", "async functions", startref="type-infer-async")))((("type inference", "callbacks", startref="type-infer-callback")))((("type inference", "Promises", startref="type-infer-promise")))((("async functions", startref="async-function")))((("callbacks", "async functions instead", startref="callback-async")))((("Promises", startref="promises")))((("await keyword", startref="await")))declare it `async`.



[[inference-sites]]
=== Item 28: Use Classes and Currying to Create [.keep-together]#New Inference Sites#

Suppose ((("type inference", "separating from explicit typing", id="type-infer-separate")))((("explicit type definitions", id="explicit-type-separate")))you define an API using a TypeScript `interface`:

// verifier:prepend-id-to-following:seed-interface
// verifier:prepend-to-following
[[seed-api-interface]]
[source,ts]
----
export interface SeedAPI {
  '/seeds': Seed[];
  '/seed/apple': Seed;
  '/seed/strawberry': Seed;
  // ...
}
----

This says that our API has a `/seeds` endpoint that returns an array of `Seed` objects. The `/seed/apple` and `/seed/strawberry` endpoints return one `Seed` object.

Let's write a function that issues requests to our API endpoints. This function should check that the endpoints exist, and it should return the correct type of data. This will be extremely helpful for making safe API calls from the client.

Here's how that function should work:

// verifier:skip since we haven't defined the function yet.
[source,ts]
----
// Correct usage:
const berry = await fetchAPI<SeedAPI>('/seed/strawberry'); // OK, returns Seed

// Incorrect usage; these should be errors:
fetchAPI<SeedAPI>('/seed/chicken');  // endpoint doesn't exist
const seed: Seed = await fetchAPI<SeedAPI>('/seeds'); // wrong return type
----

Here's how you might declare `fetchAPI` (we're not concerned about the implementation here, just the types):

// verifier:prepend-to-following
[source,ts]
----
declare function fetchAPI<
  API, Path extends keyof API
>(path: Path): Promise<API[Path]>;
----

Unfortunately, when you try to use this, you'll get an error:

[source,ts]
----
fetchAPI<SeedAPI>('/seed/strawberry');
//       ~~~~~~~ Expected 2 type arguments, but got 1.
----

The problem is that type inference in TypeScript is an all or nothing affair: either you can let TypeScript infer _all_ the type parameters from usage, or you can specify all of them explicitly. There's no in-between. (You can provide a default value for a type parameter, but this can only reference other type parameters; it can't be inferred from usage.)

// TK2 reread that previous paragraph. Does the caveat make sense or does it need to be spelled out with an example? (See how the handbook / Basarat explain this.)

The `API` type parameter could be anything: since we'd like `fetchAPI` to work with any API, it can't possibly be inferred. It has to be specified explicitly. So it would seem the only solution here is to write the `Path` type explicitly, too:

[source,ts]
----
const berry = fetchAPI<SeedAPI, '/seed/strawberry'>('/seed/strawberry');  // ok
//    ^? const berry: Promise<Seed>
----

This works, but it's frustratingly repetitive. Surely there's a better way. We need to somehow separate the place where we explicitly write the `API` type parameter from the place where we infer the `Path` type parameter.

There are two standard ways to do this: classes and currying.

[role="notoc"]
==== Classes

Classes are ((("classes", "type inference and explicit typing", id="classes-type-infer")))very good at capturing bits of state. They spare you from having to repeatedly pass the same state to a set of related functions (the class's methods). In TypeScript, it turns out that classes are also very good at capturing _types_.

Here's how you can define a class to solve this problem:

// verifier:prepend-to-following
[source,ts]
----
declare class ApiFetcher<API> {
  fetch<Path extends keyof API>(path: Path): Promise<API[Path]>;
}
----

And here's how you use it:

// verifier:tsconfig:module=ES2022
// verifier:tsconfig:target=ES2017
[source,ts]
----
const fetcher = new ApiFetcher<SeedAPI>();
const berry = await fetcher.fetch('/seed/strawberry'); // OK
//    ^? const berry: Seed

fetcher.fetch('/seed/chicken');
//            ~~~~~~~~~~~~~~~
// Argument of type '"/seed/chicken"' is not assignable to type 'keyof SeedAPI'

const seed: Seed = await fetcher.fetch('/seeds');
//    ~~~~ Seed[] is not assignable to Seed
----

This produces exactly the errors we were hoping for. (You also need to implement the class, of course! We're just focusing on the types here.)

What used to be a function that needed two generic type parameters is now a class with one generic type parameter that you specify explicitly, and a method with one generic type parameter that's inferred. TypeScript is perfectly happy to let you bind the `API` type parameter when you call the class's constructor (++new ApiFetcher&#x200b;&lt;See&#x2060;dAPI&gt;()++) and then infer `Path` when you call the `fetch` method.

Using classes to create a distinct binding site is particularly effective when you have multiple methods that all require the same ((("classes", "type inference and explicit typing", startref="classes-type-infer")))type parameter.

// TODO: This would seem to go against the advice to not write classes whose names end with "er".

[role="notoc"]
==== Currying

Fun fact: ((("currying", id="currying")))programming languages don't really need functions with more than one parameter. Instead of:

[source,ts]
----
declare function getDate(mon: string, day: number): Date;
getDate('dec', 25);
----

you could write a function that returns another function:

[source,ts]
----
declare function getDate(mon: string): (day: number) => Date;
getDate('dec')(25);
----

Note the slightly different syntax to call the second version. This practice is known as _currying_, after the logician Haskell Curry, who always disavowed having come up with the technique.

Currying gives us the flexibility we need to introduce as many inference sites as we like. Each function call can infer new type parameters.

Here's how you can rework `fetchAPI` using functions that return functions:

// verifier:reset
// verifier:prepend-id-to-following:seed-interface
// verifier:prepend-id-to-following:seed-api-interface
// verifier:prepend-to-following
[source,ts]
----
declare function fetchAPI<API>():
  <Path extends keyof API>(path: Path) => Promise<API[Path]>;
----

Now `fetchAPI` takes _no_ parameters, but it returns a function that takes one. Here's how you use it:

// verifier:tsconfig:module=ES2022
// verifier:tsconfig:target=ES2017
[source,ts]
----
const berry = await fetchAPI<SeedAPI>()('/seed/strawberry'); // OK
//    ^? const berry: Seed

fetchAPI<SeedAPI>()('/seed/chicken');
//                  ~~~~~~~~~~~~~~~
// Argument of type '"/seed/chicken"' is not assignable to type 'keyof SeedAPI'
//
const seed: Seed = await fetchAPI<SeedAPI>()('/seeds');
//    ~~~~ Seed[] is not assignable to Seed
----

Just like the class solution, this works in the case where we want it to and produces the desired error in the others. You can use an intermediate variable to separate out the two function calls to reduce repetition:

[source,ts]
----
const fetchSeedAPI = fetchAPI<SeedAPI>();
const berry = await fetchSeedAPI('/seed/strawberry');
//    ^? const berry: Seed
----

The currying approach isn't as distinct from the class approach as it might initially appear. If you use a different name and return an object type instead of a function, they look nearly identical:

[source,ts]
----
declare function apiFetcher<API>(): {
  fetch<Path extends keyof API>(path: Path): Promise<API[Path]>;
}

const fetcher = apiFetcher<SeedAPI>();
fetcher.fetch('/seed/strawberry');  // ok
----

The only difference in usage between this and the class example is the keyword `new`.

If you want to specify some generic parameters explicitly while allowing others to be inferred, classes and currying are your two options.

So which one should you prefer? Ultimately it's up to you. Whichever one feels most comfortable and produces the API you find most convenient is the way to go. The currying approach does have at least one advantage in the context of TypeScript, however: it creates a scope in which you can define ((("local type aliases")))local type aliases:

// verifier:reset
// verifier:prepend-id-to-following:seed-interface
// verifier:prepend-id-to-following:seed-api-interface
[source,ts]
----
function fetchAPI<API>() {
  type Routes = keyof API & string;  // local type alias

  return <Path extends Routes>(
    path: Path
  ): Promise<API[Path]> => fetch(path).then(r => r.json());
}
----

You can't do this with just a declaration: only the implementation introduces a new scope. Local type aliases like `Routes` can cut down on repetition involving complex type expressions. There is no equivalent of this ((("currying", startref="currying")))for classes.

[role="notoc"]
==== Things to Remember

- For functions with multiple type parameters, inference is all or nothing: either all type parameters are inferred or all must be specified explicitly.
- To get partial inference, use either classes or currying to create a new inference site.
- Prefer the currying approach if you'd like to create a ((("type inference", "separating from explicit typing", startref="type-infer-separate")))((("explicit type definitions", startref="explicit-type-separate")))local type alias.

////
// verifier:reset
[[seed-interface]]
[source,ts]
----
interface Seed {
  id: string;
  name: string;
}
----
////
